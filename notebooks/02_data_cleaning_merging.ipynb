{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8793f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Milestone 2: Feature Engineering & Data Wrangling ---\n",
      "Project base path identified as: c:\\Users\\RAVI TEJA\\OneDrive\\Desktop\\Infosys Internship 6.0\\azure-demand-forecasting\n",
      "Searching for data file at: c:\\Users\\RAVI TEJA\\OneDrive\\Desktop\\Infosys Internship 6.0\\azure-demand-forecasting\\data\\processed\\cleaned_merged.csv\n",
      "\n",
      "Successfully loaded 'cleaned_merged.csv'.\n",
      "Creating time-based features (day of week, month, year-week)...\n",
      "Creating 7-day rolling average for CPU usage...\n",
      "\n",
      "Successfully created new features and saved the file to: c:\\Users\\RAVI TEJA\\OneDrive\\Desktop\\Infosys Internship 6.0\\azure-demand-forecasting\\data\\processed\\featured_dataset.csv\n",
      "\n",
      "--- Sample of the new 'featured_dataset.csv' with new columns: ---\n",
      "         date  day_of_week  month year_week  cpu_usage_7_day_avg\n",
      "2  2023-01-01            6      1  2022-W52                 70.0\n",
      "14 2023-01-02            0      1  2023-W01                 78.0\n",
      "26 2023-01-03            1      1  2023-W01                 71.0\n",
      "38 2023-01-04            2      1  2023-W01                 67.5\n",
      "50 2023-01-05            3      1  2023-W01                 71.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- Milestone 2: Feature Engineering & Data Wrangling ---\")\n",
    "\n",
    "# --- 1. Define File Paths ---\n",
    "# This path logic works when the notebook is in the 'notebooks' folder\n",
    "try:\n",
    "    current_dir = os.getcwd()\n",
    "    base_path = os.path.dirname(current_dir)\n",
    "    processed_data_path = os.path.join(base_path, 'data', 'processed', 'cleaned_merged.csv')\n",
    "    output_path = os.path.join(base_path, 'data', 'processed', 'featured_dataset.csv')\n",
    "    print(f\"Project base path identified as: {base_path}\")\n",
    "    print(\"Searching for data file at:\", processed_data_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up file paths: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Load the Cleaned Dataset ---\n",
    "try:\n",
    "    df = pd.read_csv(processed_data_path)\n",
    "    print(f\"\\nSuccessfully loaded '{os.path.basename(processed_data_path)}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nError: The file was not found at {processed_data_path}\")\n",
    "    print(\"Please ensure 'cleaned_merged.csv' exists in your 'data/processed' folder from Milestone 1.\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Engineer Derived Features ---\n",
    "print(\"Creating time-based features (day of week, month, year-week)...\")\n",
    "# Ensure the 'date' column is in datetime format for feature extraction\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df['day_of_week'] = df['date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['month'] = df['date'].dt.month\n",
    "\n",
    "# Get the full ISO calendar data (year, week, day) to handle year-end weeks correctly\n",
    "iso_cal = df['date'].dt.isocalendar()\n",
    "# Create a sortable year-week string (e.g., \"2023-W05\")\n",
    "df['year_week'] = iso_cal.year.astype(str) + '-W' + iso_cal.week.astype(str).str.zfill(2)\n",
    "# Keep the simple week number for other calculations if needed\n",
    "df['week_of_year'] = iso_cal.week\n",
    "\n",
    "# --- 4. Create Rolling Average (Trend) Feature ---\n",
    "print(\"Creating 7-day rolling average for CPU usage...\")\n",
    "# Sort data to ensure correct rolling calculations for time-series data\n",
    "df = df.sort_values(by=['region', 'resource_type', 'date'])\n",
    "\n",
    "# Calculate a 7-day rolling average of CPU usage.\n",
    "# We group by each specific resource in each region to get an accurate trend.\n",
    "df['cpu_usage_7_day_avg'] = df.groupby(['region', 'resource_type'])['usage_cpu'].transform(\n",
    "    lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "# --- 5. Save the Enriched, Model-Ready Dataset ---\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nSuccessfully created new features and saved the file to: {output_path}\")\n",
    "\n",
    "# --- Display the first few rows of the new dataset to verify ---\n",
    "print(\"\\n--- Sample of the new 'featured_dataset.csv' with new columns: ---\")\n",
    "print(df[['date', 'day_of_week', 'month', 'year_week', 'cpu_usage_7_day_avg']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
